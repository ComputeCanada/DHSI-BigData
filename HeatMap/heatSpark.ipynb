{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Function\n",
    "Here we'll build and hold entire single row numpy arrays that can easily be passed to the reducer and added there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heatMap(file):\n",
    "    for line in file:\n",
    "        try:\n",
    "            # remove leading and trailing whitespace\n",
    "            line = line.strip()\n",
    "            m = re.search(regEx, line)\n",
    "            if m != None:\n",
    "                #print(m.group(0),m.group(1),m.group(2))\n",
    "                if m.group(2).lower() == searchTerm:\n",
    "                    # split m.group(1) at the commas\n",
    "                    coords = [int(i) for i in m.group(1).split(',')] #nice use of list comprehension to convert to ints\n",
    "                    # create a numpy array that is one row\n",
    "                    for row in range(coords[0],coords[2]+1):\n",
    "                        print('%s\\t%s,%s' % (row, coords[1],coords[3]))\n",
    "\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Function\n",
    "Since we have used full arrays in the map function the reduce function is just a matter of summing them, which the numpy array data type makes a snap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def heatReduce(a,b)\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "#sqlContext = pyspark.SQLContext(sc)\n",
    "\n",
    "import numpy as np\n",
    "frontPage = np.zeros((7000,5250)) \n",
    "#frontPage.dtype\n",
    "frontPage = frontPage.astype('uint32')\n",
    "#frontPage.dtype\n",
    "\n",
    "searchTerm = input(\"Please enter a single word that you would like to search the London Times for:\")\n",
    "searchTerm = searchTerm.lower()\n",
    "\n",
    "\n",
    "# input comes from STDIN (standard input)\n",
    "#for line in sys.stdin:\n",
    "\n",
    "# read from regular file for testing\n",
    "\n",
    "import os\n",
    "ocrData = os.path.dirname(\"Data/OCRText39-45/\")\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "def searchXML(searchTerm, file):\n",
    "    #print(file)\n",
    "    try:\n",
    "        tree = etree.parse(file)\n",
    "        MyXpath = '//p[preceding-sibling::pg[@pgref=1]]/wd[translate(text(), \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", \"abcdefghijklmnopqrstuvwxyz\")=\"' + searchTerm + '\"]/@pos'\n",
    "\n",
    "        find_text = etree.XPath(MyXpath)\n",
    "        # print(find_text)\n",
    "        foundPOS = find_text(tree)\n",
    "        # print(foundPOS)\n",
    "        if foundPOS != []:\n",
    "            for pos in foundPOS:\n",
    "                posList = str(pos).split(',')\n",
    "                posList = [int(item) for item in posList]\n",
    "                #print(pos,posList)\n",
    "                frontPage[posList[1]-1:posList[3],posList[0]-1:posList[2]] += 1\n",
    "                #print(frontPage[posList[0]-2:posList[2]+1,posList[1]-2:posList[3]+1])\n",
    "    except:\n",
    "        print(\"Likely XMLSyntax Error in\", file, \", skipping\") \n",
    "\n",
    "for root, dirs, files in os.walk(ocrData):\n",
    "    for file in files:\n",
    "        if file.endswith(\".xml\") and file.startswith(\"0FFO\"):\n",
    "            #print(os.path.join(root, file))\n",
    "            searchXML(searchTerm,os.path.join(root, file))\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.figure(figsize=(500, 200))\n",
    "image  = plt.imshow(frontPage)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  2.  2.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a,b = np.zeros(10),np.zeros(10)\n",
    "a[3:6] += 1\n",
    "b[4:7] += 1\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
